# ğŸ“§ InboxIQ Backend

<div align="center">

**ClassificaÃ§Ã£o inteligente de emails com IA e sugestÃµes automÃ¡ticas de resposta**

[![FastAPI](https://img.shields.io/badge/FastAPI-005571?style=for-the-badge&logo=fastapi)](https://fastapi.tiangolo.com/)
[![OpenAI](https://img.shields.io/badge/OpenAI-412991?style=for-the-badge&logo=openai&logoColor=white)](https://openai.com/)
[![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://python.org/)
[![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white)](https://docker.com/)

</div>

---

## ğŸ¯ Sobre o Projeto

Backend desenvolvido para o case **AutoU** que automatiza a triagem de alto volume de emails, classificando-os como **Produtivo** ou **Improdutivo** e gerando **sugestÃµes de resposta automÃ¡tica** utilizando GPT da OpenAI.

### Por que InboxIQ?

- âš¡ **Reduz esforÃ§o manual** da equipe de suporte
- ğŸ¯ **Prioriza emails importantes** automaticamente
- ğŸ¤– **SugestÃµes de resposta** com formataÃ§Ã£o profissional
- ğŸ“„ **Suporte a mÃºltiplos formatos** (texto, PDF)
- ğŸ›¡ï¸ **Fallback robusto** quando a IA nÃ£o estÃ¡ disponÃ­vel

---

## âœ¨ Funcionalidades

| Recurso | DescriÃ§Ã£o |
|---------|-----------|
| ğŸ·ï¸ **ClassificaÃ§Ã£o Inteligente** | Categoriza emails como Produtivo/Improdutivo |
| âœï¸ **SugestÃ£o de Resposta** | Gera texto formatado pronto para envio |
| ğŸ§¹ **PrÃ©-processamento NLP** | Remove stopwords e aplica lematizaÃ§Ã£o |
| ğŸ“ **Upload de Arquivos** | Aceita `.txt` e `.pdf` com extraÃ§Ã£o automÃ¡tica |
| ğŸ”„ **Sistema de Fallback** | HeurÃ­stica quando IA falha (quota/timeout) |
| ğŸ›¡ï¸ **Output Guard** | Valida e normaliza respostas da IA |
| ğŸ“Š **API Padronizada** | Envelope consistente em todas as rotas |
| ğŸ“š **DocumentaÃ§Ã£o AutomÃ¡tica** | Swagger UI integrado |

---

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API       â”‚  â† Endpoints e validaÃ§Ã£o (FastAPI)
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Services   â”‚  â† OrquestraÃ§Ã£o do fluxo
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Providers               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ EmailReader (TXT/PDF)         â”‚
â”‚ â€¢ NlpPreprocess (LematizaÃ§Ã£o)   â”‚
â”‚ â€¢ OpenAiEmailProvider (IA)      â”‚
â”‚ â€¢ HeuristicFallbackProvider     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Camadas

- **API (routes)**: Define endpoints REST e valida payload
- **Services**: Orquestra NLP â†’ IA â†’ Guard â†’ Resposta
- **Providers**: Componentes especializados (leitura, processamento, IA)
- **Policies**: `PromptPolicy` centraliza instruÃ§Ãµes para consistÃªncia
- **Middlewares**: PadronizaÃ§Ã£o de erros e tratamento de falhas

---

## ğŸ”Œ API Endpoints

### ğŸ“ Analisar Texto

```http
POST /emails/analyze
Content-Type: application/json

{
  "text": "Boa tarde, gostaria de saber o status do meu chamado..."
}
```

### ğŸ“ Analisar Arquivo

```http
POST /emails/analyze-file
Content-Type: multipart/form-data

file: arquivo.pdf ou arquivo.txt
```

### ğŸ“¦ Formato de Resposta

**Sucesso:**
```json
{
  "success": true,
  "message": "Email analisado com sucesso.",
  "data": {
    "category": "Produtivo",
    "suggested_reply": "OlÃ¡...\n\nAtenciosamente,\n[Seu nome]",
    "confidence": 0.94
  },
  "errors": null
}
```

**Erro:**
```json
{
  "success": false,
  "message": "Erro de validaÃ§Ã£o.",
  "data": null,
  "errors": [
    {
      "code": "VALIDATION_ERROR",
      "message": "Campo obrigatÃ³rio",
      "field": "text"
    }
  ]
}
```

---

## ğŸš€ ComeÃ§ando

### PrÃ©-requisitos

- Python 3.9+
- Chave de API da OpenAI
- (Opcional) Docker

### âš™ï¸ ConfiguraÃ§Ã£o

1. **Clone o repositÃ³rio**
```bash
git clone <seu-repo>
cd InboxIQ/backend
```

2. **Crie o ambiente virtual**
```powershell
python -m venv .venv
.\.venv\Scripts\Activate.ps1  # Windows
# ou
source .venv/bin/activate      # Linux/Mac
```

3. **Instale as dependÃªncias**
```bash
pip install -r requirements.txt
```

4. **Configure as variÃ¡veis de ambiente**

Crie um arquivo `.env` na raiz do backend:

```env
# App
APP_NAME=AutoU InboxIQ API
APP_VERSION=0.1.0

# CORS (separado por vÃ­rgula)
ALLOWED_ORIGINS=http://localhost:3000,https://seu-front.vercel.app

# OpenAI
OPENAI_API_KEY=sk-proj-...
OPENAI_MODEL=gpt-4o-mini
OPENAI_BASE_URL=
OPENAI_TIMEOUT=30
```

> âš ï¸ **Importante**: Nunca commite o arquivo `.env` no Git!

---

## ğŸ’» Rodando Localmente

### Modo Desenvolvimento

```powershell
# Windows
python -m uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

# Linux/Mac
python -m uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

Acesse:
- ğŸŒ API: http://localhost:8000
- ğŸ“š Swagger UI: http://localhost:8000/docs
- ğŸ“‹ OpenAPI JSON: http://localhost:8000/openapi.json

---

## ğŸ³ Rodando com Docker

### Build da Imagem

```bash
cd backend
docker build -t autou-inboxiq-api .
```

### Executar Container

```bash
docker run --rm -p 8000:8000 --env-file .env autou-inboxiq-api
```

Acesse: http://localhost:8000/docs

---

## ğŸ§ª Testando a API

### Com cURL

```bash
# AnÃ¡lise de texto
curl -X POST http://localhost:8000/emails/analyze \
  -H "Content-Type: application/json" \
  -d '{"text": "Gostaria de saber o status do meu pedido #1234"}'

# Upload de arquivo
curl -X POST http://localhost:8000/emails/analyze-file \
  -F "file=@email.pdf"
```

### Com Postman

1. **POST** `/emails/analyze`
   - Headers: `Content-Type: application/json`
   - Body (raw JSON):
   ```json
   {
     "text": "Boa tarde, gostaria de saber o status do meu chamado..."
   }
   ```

2. **POST** `/emails/analyze-file`
   - Body: form-data
   - Key: `file` (tipo File)
   - Value: selecione arquivo `.pdf` ou `.txt`

---

## ğŸ§  Pipeline de Processamento NLP

O backend aplica processamento antes de enviar para a IA:

```
Email Original
    â†“
1. NormalizaÃ§Ã£o
    â†“
2. TokenizaÃ§Ã£o
    â†“
3. RemoÃ§Ã£o de Stopwords (PT/EN)
    â†“
4. LematizaÃ§Ã£o (simplemma)
    â†“
5. ExtraÃ§Ã£o de Keywords
    â†“
OpenAI GPT (com prompt otimizado)
    â†“
Output Guard (validaÃ§Ã£o)
    â†“
Resposta Final
```

> ğŸ’¡ O texto original Ã© preservado para manter contexto e formataÃ§Ã£o natural na resposta

---

## ğŸ“ Estrutura do Projeto

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                 # AplicaÃ§Ã£o FastAPI
â”‚   â”œâ”€â”€ routes/                 # Endpoints da API
â”‚   â”œâ”€â”€ services/               # LÃ³gica de negÃ³cio
â”‚   â”œâ”€â”€ providers/              # Componentes especializados
â”‚   â”œâ”€â”€ policies/               # PolÃ­ticas de prompt
â”‚   â””â”€â”€ middlewares/            # Tratamento de erros
â”œâ”€â”€ .env                        # VariÃ¡veis de ambiente (nÃ£o versionar!)
â”œâ”€â”€ requirements.txt            # DependÃªncias Python
â”œâ”€â”€ Dockerfile                  # Container Docker
â””â”€â”€ README.md                   # VocÃª estÃ¡ aqui!
```

---

## ğŸ›¡ï¸ Recursos de Robustez

- âœ… **Fallback HeurÃ­stico**: Sistema de backup quando IA falha
- âœ… **Output Guard**: Valida categoria, tamanho e conteÃºdo
- âœ… **Timeout ConfigurÃ¡vel**: Previne travamentos
- âœ… **Tratamento de Erros**: Respostas padronizadas
- âœ… **ValidaÃ§Ã£o de Input**: Pydantic schemas
- âœ… **Rate Limiting Ready**: Preparado para limitaÃ§Ã£o de requisiÃ§Ãµes

---

## ğŸ” Observabilidade

### Logging Estruturado (JSON)

Todos os logs sÃ£o emitidos em **formato JSON** para facilitar indexaÃ§Ã£o e filtragem em ferramentas como AWS CloudWatch, ELK Stack, Datadog, etc.

#### Campos Padronizados

Cada entrada de log inclui:

| Campo | DescriÃ§Ã£o | Exemplo |
|-------|-----------|---------|
| `ts` | Timestamp UTC | `2026-01-15T14:30:45.123Z` |
| `level` | NÃ­vel do log | `INFO`, `ERROR`, `WARNING` |
| `logger` | Origem do log | `app.http`, `app.external_ai` |
| `msg` | Mensagem descritiva | `Request completed successfully` |
| `event` | Tipo do evento | `request_start`, `openai_rate_limit` |
| `correlation_id` | ID Ãºnico da requisiÃ§Ã£o | `550e8400-e29b-41d4-a716-446655440000` |

**Metadados adicionais:** `method`, `path`, `status_code`, `duration_ms`, `client_ip`

#### Exemplo de Log JSON

```json
{
  "ts": "2026-01-15T14:30:45.123Z",
  "level": "INFO",
  "logger": "app.http",
  "msg": "Request completed",
  "event": "request_end",
  "correlation_id": "550e8400-e29b-41d4-a716-446655440000",
  "method": "POST",
  "path": "/emails/analyze",
  "status_code": 200,
  "duration_ms": 1250,
  "client_ip": "192.168.1.100"
}
```

### ğŸ”— Correlation ID (X-Correlation-Id)

Cada requisiÃ§Ã£o recebe um **identificador Ãºnico** para rastreamento ponta a ponta:

**Como funciona:**

1. Cliente envia header `X-Correlation-Id` â†’ Backend reutiliza o valor
2. Sem header â†’ Backend gera UUID automaticamente
3. Header Ã© retornado na resposta para captura pelo cliente

**BenefÃ­cios:**

- ğŸ” Rastreie todos os logs de uma requisiÃ§Ã£o especÃ­fica
- ğŸ› Debugging facilitado em ambientes distribuÃ­dos
- ğŸ“Š CorrelaÃ§Ã£o entre frontend e backend
- âš¡ DiagnÃ³stico rÃ¡pido de erros em produÃ§Ã£o

**Exemplo de uso:**

```bash
# Cliente envia correlation ID
curl -X POST http://localhost:8000/emails/analyze \
  -H "X-Correlation-Id: meu-id-customizado-123" \
  -H "Content-Type: application/json" \
  -d '{"text": "teste"}'

# Response header inclui:
# X-Correlation-Id: meu-id-customizado-123
```

### ğŸ“ Logs por RequisiÃ§Ã£o

O middleware registra **dois eventos** por requisiÃ§Ã£o:

#### 1. Request Start
```json
{
  "event": "request_start",
  "method": "POST",
  "path": "/emails/analyze",
  "correlation_id": "abc-123"
}
```

#### 2. Request End (com duraÃ§Ã£o)
```json
{
  "event": "request_end",
  "method": "POST",
  "path": "/emails/analyze",
  "status_code": 200,
  "duration_ms": 1250,
  "correlation_id": "abc-123"
}
```

### âš ï¸ Tratamento de ExceÃ§Ãµes Externas (OpenAI)

O middleware captura e registra erros do provedor de IA com logs consistentes:

**CenÃ¡rios tratados:**

- ğŸ”‘ **Auth Error**: Chave de API invÃ¡lida
- ğŸš« **Rate Limit/Quota**: Limite de requisiÃ§Ãµes/cota excedida
- â±ï¸ **Timeout**: RequisiÃ§Ã£o demorou demais
- âŒ **Status Errors**: Erros HTTP diversos

**Exemplo de log de erro:**

```json
{
  "ts": "2026-01-15T14:35:12.456Z",
  "level": "ERROR",
  "logger": "app.external_ai",
  "msg": "OpenAI rate limit exceeded",
  "event": "openai_rate_limit",
  "correlation_id": "550e8400-e29b-41d4-a716-446655440000",
  "status_code": 429,
  "provider_request_id": "req_abc123xyz",
  "exception": "RateLimitError: Rate limit exceeded...",
  "traceback": "..."
}
```

**CaracterÃ­sticas:**

- âœ… Registra stacktrace completo
- âœ… Inclui `provider_request_id` quando disponÃ­vel
- âœ… MantÃ©m envelope padronizado na resposta
- âœ… Preserva `correlation_id` para rastreamento

### âš™ï¸ ConfiguraÃ§Ã£o de Logging

Adicione ao arquivo `.env`:

```env
# Logging
LOG_LEVEL=INFO          # DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_JSON=true           # true para JSON estruturado, false para texto
```

**NÃ­veis recomendados por ambiente:**

| Ambiente | LOG_LEVEL | LOG_JSON |
|----------|-----------|----------|
| Desenvolvimento | `DEBUG` | `false` |
| HomologaÃ§Ã£o | `INFO` | `true` |
| ProduÃ§Ã£o | `INFO` | `true` |

### ğŸ¯ BenefÃ­cios da Observabilidade

| BenefÃ­cio | DescriÃ§Ã£o |
|-----------|-----------|
| ğŸ” **Troubleshooting RÃ¡pido** | Filtre logs por `correlation_id` para ver toda a jornada da requisiÃ§Ã£o |
| ğŸ“Š **MÃ©tricas de Performance** | Analise `duration_ms` para identificar gargalos |
| ğŸš¨ **Alertas Proativos** | Configure alertas baseados em `event` e `status_code` |
| ğŸ”— **Rastreamento DistribuÃ­do** | Propague `correlation_id` entre microserviÃ§os |
| ğŸ› ï¸ **Suporte Eficiente** | Equipe de suporte pode usar `correlation_id` do erro reportado |
| ğŸ“ˆ **AnÃ¡lise de TendÃªncias** | Logs estruturados facilitam agregaÃ§Ãµes e dashboards |

### ğŸ”§ Exemplo de Troubleshooting

**CenÃ¡rio:** Cliente reporta erro no request

1. Cliente fornece `correlation_id` do header de resposta
2. Filtre logs: `correlation_id == "550e8400-e29b-41d4-a716-446655440000"`
3. Veja toda a jornada: request_start â†’ processamento â†’ erro â†’ request_end
4. Identifique stacktrace e contexto completo

**Query exemplo (CloudWatch Insights):**

```sql
fields @timestamp, level, msg, event, duration_ms
| filter correlation_id = "550e8400-e29b-41d4-a716-446655440000"
| sort @timestamp asc
```

---

## ğŸ“ LicenÃ§a

Este projeto foi desenvolvido como case para **AutoU**.

---

<div align="center">

**Desenvolvido com â¤ï¸ usando FastAPI e OpenAI**

[DocumentaÃ§Ã£o](http://localhost:8000/docs) â€¢ [Reportar Bug](issues) â€¢ [Sugerir Feature](issues)

</div>
